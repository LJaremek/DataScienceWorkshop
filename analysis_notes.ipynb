{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enum class for model types: nano, medium, large\n",
    "from enum import Enum\n",
    "\n",
    "class ModelType(str, Enum):\n",
    "    NANO = \"nano\"\n",
    "    MEDIUM = \"med\"\n",
    "    LARGE = \"large\"\n",
    "\n",
    "model_type = ModelType.MEDIUM\n",
    "\n",
    "model_name = f\"./runs/obb/train_{model_type}/weights/best.pt\"\n",
    "model = YOLO(model_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Dokumenty\\AAA_PW\\Sem10\\DataScienceWorkshop\\data\\0\\cropped_gm.png: 608x640 16.1ms\n",
      "Speed: 2.7ms preprocess, 16.1ms inference, 3.4ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    }
   ],
   "source": [
    "img = \"./data/0/cropped_gm.png\"\n",
    "\n",
    "results = model.predict(img, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.OBB object with attributes:\n",
       "\n",
       "cls: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
       "conf: tensor([0.6303, 0.6038, 0.5493, 0.5205, 0.4986, 0.4962, 0.4800, 0.4643, 0.4585, 0.4552, 0.4524, 0.4467, 0.4226, 0.3856, 0.3780, 0.3467, 0.3412, 0.3339, 0.3094, 0.3085, 0.3020, 0.2984, 0.2870, 0.2841, 0.2753, 0.2708, 0.2619, 0.2576, 0.2533, 0.2518], device='cuda:0')\n",
       "data: tensor([[4.2416e+02, 3.0202e+02, 4.1166e+01, 1.9782e+01, 8.4108e-01, 6.3033e-01, 1.0000e+00],\n",
       "        [4.0638e+02, 3.1797e+02, 4.2245e+01, 2.0488e+01, 8.5422e-01, 6.0382e-01, 1.0000e+00],\n",
       "        [4.6245e+02, 5.2175e+01, 1.2928e+01, 8.2947e+00, 1.5448e+00, 5.4925e-01, 1.0000e+00],\n",
       "        [6.2948e+02, 6.5695e+02, 4.2303e+01, 2.0364e+01, 2.8228e-01, 5.2054e-01, 1.0000e+00],\n",
       "        [4.7589e+02, 5.2673e+01, 1.4521e+01, 9.6756e+00, 1.5554e+00, 4.9865e-01, 1.0000e+00],\n",
       "        [4.3980e+02, 5.0393e+01, 1.4698e+01, 7.5050e+00, 1.5394e+00, 4.9624e-01, 1.0000e+00],\n",
       "        [9.3987e+02, 1.9304e+01, 9.2252e+00, 1.7551e+01, 2.1650e-02, 4.7997e-01, 1.0000e+00],\n",
       "        [3.9827e+02, 5.1338e+01, 1.3388e+01, 8.9329e+00, 1.5499e+00, 4.6427e-01, 1.0000e+00],\n",
       "        [4.4359e+02, 2.8177e+02, 4.1401e+01, 2.1480e+01, 6.8493e-01, 4.5852e-01, 1.0000e+00],\n",
       "        [9.2493e+02, 2.0065e+01, 8.8530e+00, 1.5018e+01, 2.1348e-02, 4.5522e-01, 1.0000e+00],\n",
       "        [9.1240e+02, 2.0414e+01, 8.5692e+00, 1.5253e+01, 9.5904e-03, 4.5245e-01, 1.0000e+00],\n",
       "        [4.2720e+02, 5.0848e+01, 1.4767e+01, 8.2751e+00, 1.5355e+00, 4.4669e-01, 1.0000e+00],\n",
       "        [4.5295e+02, 5.1286e+01, 1.3866e+01, 7.4628e+00, 1.5517e+00, 4.2260e-01, 1.0000e+00],\n",
       "        [3.8511e+02, 5.0967e+01, 1.6000e+01, 1.0085e+01, 1.5666e+00, 3.8561e-01, 1.0000e+00],\n",
       "        [9.0954e+02, 5.1286e+01, 8.1485e+00, 1.2833e+01, 3.5180e-02, 3.7803e-01, 1.0000e+00],\n",
       "        [9.5475e+02, 1.9254e+01, 1.4905e+01, 7.9771e+00, 1.5601e+00, 3.4667e-01, 1.0000e+00],\n",
       "        [6.3659e+02, 6.3604e+02, 4.0857e+01, 1.9841e+01, 3.0974e-01, 3.4121e-01, 1.0000e+00],\n",
       "        [9.7481e+02, 2.0183e+01, 7.7157e+00, 1.5474e+01, 8.1172e-03, 3.3385e-01, 1.0000e+00],\n",
       "        [9.6362e+02, 1.9225e+01, 1.5181e+01, 7.3410e+00, 1.5700e+00, 3.0936e-01, 1.0000e+00],\n",
       "        [4.1070e+02, 5.1770e+01, 1.3408e+01, 8.8789e+00, 1.5359e+00, 3.0855e-01, 1.0000e+00],\n",
       "        [9.2103e+02, 5.2645e+01, 7.9350e+00, 1.2575e+01, 4.1717e-02, 3.0203e-01, 1.0000e+00],\n",
       "        [7.3596e+02, 3.6306e+02, 1.9168e+01, 3.9824e+01, 1.2036e+00, 2.9837e-01, 1.0000e+00],\n",
       "        [9.8460e+02, 2.0496e+01, 1.5786e+01, 8.0342e+00, 1.5566e+00, 2.8703e-01, 1.0000e+00],\n",
       "        [4.9104e+02, 5.2744e+01, 9.0723e+00, 1.3892e+01, 1.6395e-02, 2.8409e-01, 1.0000e+00],\n",
       "        [6.1047e+02, 5.0317e+01, 1.4964e+01, 8.7526e+00, 1.5460e+00, 2.7532e-01, 1.0000e+00],\n",
       "        [5.0412e+02, 6.0677e+02, 4.3981e+01, 2.1623e+01, 2.9474e-01, 2.7079e-01, 1.0000e+00],\n",
       "        [5.9171e+02, 6.2637e+02, 4.3459e+01, 2.0946e+01, 3.1780e-01, 2.6190e-01, 1.0000e+00],\n",
       "        [6.0318e+02, 7.5027e+02, 4.3594e+01, 1.8684e+01, 6.7318e-01, 2.5757e-01, 1.0000e+00],\n",
       "        [8.1831e+02, 1.1773e+02, 6.7158e+00, 1.1928e+01, 1.1995e-02, 2.5329e-01, 1.0000e+00],\n",
       "        [8.4586e+02, 1.1748e+02, 6.3644e+00, 1.0268e+01, 3.8815e-02, 2.5178e-01, 1.0000e+00]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (954, 1048)\n",
       "shape: torch.Size([30, 7])\n",
       "xywhr: tensor([[4.2416e+02, 3.0202e+02, 4.1166e+01, 1.9782e+01, 8.4108e-01],\n",
       "        [4.0638e+02, 3.1797e+02, 4.2245e+01, 2.0488e+01, 8.5422e-01],\n",
       "        [4.6245e+02, 5.2175e+01, 1.2928e+01, 8.2947e+00, 1.5448e+00],\n",
       "        [6.2948e+02, 6.5695e+02, 4.2303e+01, 2.0364e+01, 2.8228e-01],\n",
       "        [4.7589e+02, 5.2673e+01, 1.4521e+01, 9.6756e+00, 1.5554e+00],\n",
       "        [4.3980e+02, 5.0393e+01, 1.4698e+01, 7.5050e+00, 1.5394e+00],\n",
       "        [9.3987e+02, 1.9304e+01, 9.2252e+00, 1.7551e+01, 2.1650e-02],\n",
       "        [3.9827e+02, 5.1338e+01, 1.3388e+01, 8.9329e+00, 1.5499e+00],\n",
       "        [4.4359e+02, 2.8177e+02, 4.1401e+01, 2.1480e+01, 6.8493e-01],\n",
       "        [9.2493e+02, 2.0065e+01, 8.8530e+00, 1.5018e+01, 2.1348e-02],\n",
       "        [9.1240e+02, 2.0414e+01, 8.5692e+00, 1.5253e+01, 9.5904e-03],\n",
       "        [4.2720e+02, 5.0848e+01, 1.4767e+01, 8.2751e+00, 1.5355e+00],\n",
       "        [4.5295e+02, 5.1286e+01, 1.3866e+01, 7.4628e+00, 1.5517e+00],\n",
       "        [3.8511e+02, 5.0967e+01, 1.6000e+01, 1.0085e+01, 1.5666e+00],\n",
       "        [9.0954e+02, 5.1286e+01, 8.1485e+00, 1.2833e+01, 3.5180e-02],\n",
       "        [9.5475e+02, 1.9254e+01, 1.4905e+01, 7.9771e+00, 1.5601e+00],\n",
       "        [6.3659e+02, 6.3604e+02, 4.0857e+01, 1.9841e+01, 3.0974e-01],\n",
       "        [9.7481e+02, 2.0183e+01, 7.7157e+00, 1.5474e+01, 8.1172e-03],\n",
       "        [9.6362e+02, 1.9225e+01, 1.5181e+01, 7.3410e+00, 1.5700e+00],\n",
       "        [4.1070e+02, 5.1770e+01, 1.3408e+01, 8.8789e+00, 1.5359e+00],\n",
       "        [9.2103e+02, 5.2645e+01, 7.9350e+00, 1.2575e+01, 4.1717e-02],\n",
       "        [7.3596e+02, 3.6306e+02, 1.9168e+01, 3.9824e+01, 1.2036e+00],\n",
       "        [9.8460e+02, 2.0496e+01, 1.5786e+01, 8.0342e+00, 1.5566e+00],\n",
       "        [4.9104e+02, 5.2744e+01, 9.0723e+00, 1.3892e+01, 1.6395e-02],\n",
       "        [6.1047e+02, 5.0317e+01, 1.4964e+01, 8.7526e+00, 1.5460e+00],\n",
       "        [5.0412e+02, 6.0677e+02, 4.3981e+01, 2.1623e+01, 2.9474e-01],\n",
       "        [5.9171e+02, 6.2637e+02, 4.3459e+01, 2.0946e+01, 3.1780e-01],\n",
       "        [6.0318e+02, 7.5027e+02, 4.3594e+01, 1.8684e+01, 6.7318e-01],\n",
       "        [8.1831e+02, 1.1773e+02, 6.7158e+00, 1.1928e+01, 1.1995e-02],\n",
       "        [8.4586e+02, 1.1748e+02, 6.3644e+00, 1.0268e+01, 3.8815e-02]], device='cuda:0')\n",
       "xyxy: tensor([[403.0644, 280.0859, 445.2528, 323.9575],\n",
       "        [384.7808, 295.3127, 427.9767, 340.6246],\n",
       "        [458.1335,  45.6051, 466.7618,  58.7449],\n",
       "        [606.3301, 641.2769, 652.6309, 672.6181],\n",
       "        [470.9459,  45.3394, 480.8438,  60.0073],\n",
       "        [435.8151,  42.9305, 443.7772,  57.8562],\n",
       "        [935.0687,  10.4309, 944.6718,  28.1772],\n",
       "        [393.6608,  44.5518, 402.8715,  58.1233],\n",
       "        [420.7681, 260.3555, 466.4200, 303.1816],\n",
       "        [920.3467,  12.4637, 929.5183,  27.6670],\n",
       "        [908.0423,  12.7466, 916.7574,  28.0809],\n",
       "        [422.8007,  43.3233, 431.5923,  58.3731],\n",
       "        [449.0894,  44.2832, 456.8157,  58.2894],\n",
       "        [380.0305,  42.9451, 390.1828,  58.9879],\n",
       "        [905.2463,  44.7300, 913.8411,  57.8419],\n",
       "        [950.6819,  11.7594, 958.8185,  26.7492],\n",
       "        [614.1077, 620.3668, 659.0685, 651.7175],\n",
       "        [970.8864,  12.4150, 978.7275,  27.9515],\n",
       "        [959.9434,  11.6318, 967.2969,  26.8184],\n",
       "        [406.0316,  44.9158, 415.3723,  58.6251],\n",
       "        [916.8049,  46.1978, 925.2574,  59.0932],\n",
       "        [713.9320, 346.9714, 757.9823, 379.1585],\n",
       "        [980.4683,  12.5469, 988.7260,  28.4453],\n",
       "        [486.3934,  45.7246, 495.6922,  59.7633],\n",
       "        [605.9113,  42.7287, 615.0318,  57.9046],\n",
       "        [479.9361, 590.0350, 528.3013, 623.5010],\n",
       "        [567.7977, 609.6271, 615.6260, 643.1042],\n",
       "        [580.3087, 729.3728, 626.0417, 771.1610],\n",
       "        [814.8774, 111.7286, 821.7358, 123.7366],\n",
       "        [842.4782, 112.2277, 849.2363, 122.7348]], device='cuda:0')\n",
       "xyxyxyxy: tensor([[[430.5079, 323.9575],\n",
       "         [445.2528, 310.7696],\n",
       "         [417.8093, 280.0859],\n",
       "         [403.0644, 293.2738]],\n",
       "\n",
       "        [[412.5275, 340.6246],\n",
       "         [427.9767, 327.1678],\n",
       "         [400.2301, 295.3127],\n",
       "         [384.7808, 308.7695]],\n",
       "\n",
       "        [[458.4700,  58.7449],\n",
       "         [466.7618,  58.5291],\n",
       "         [466.4254,  45.6051],\n",
       "         [458.1335,  45.8210]],\n",
       "\n",
       "        [[646.9585, 672.6181],\n",
       "         [652.6309, 653.0602],\n",
       "         [612.0024, 641.2769],\n",
       "         [606.3301, 660.8348]],\n",
       "\n",
       "        [[471.1693,  60.0073],\n",
       "         [480.8438,  59.8585],\n",
       "         [480.6204,  45.3394],\n",
       "         [470.9459,  45.4883]],\n",
       "\n",
       "        [[436.2759,  57.8562],\n",
       "         [443.7772,  57.6209],\n",
       "         [443.3164,  42.9305],\n",
       "         [435.8151,  43.1658]],\n",
       "\n",
       "        [[944.2917,  28.1772],\n",
       "         [944.6718,  10.6307],\n",
       "         [935.4487,  10.4309],\n",
       "         [935.0687,  27.9775]],\n",
       "\n",
       "        [[393.9406,  58.1233],\n",
       "         [402.8715,  57.9367],\n",
       "         [402.5917,  44.5518],\n",
       "         [393.6608,  44.7385]],\n",
       "\n",
       "        [[452.8314, 303.1816],\n",
       "         [466.4200, 286.5460],\n",
       "         [434.3567, 260.3555],\n",
       "         [420.7681, 276.9911]],\n",
       "\n",
       "        [[929.1978,  27.6670],\n",
       "         [929.5183,  12.6527],\n",
       "         [920.6672,  12.4637],\n",
       "         [920.3467,  27.4780]],\n",
       "\n",
       "        [[916.6111,  28.0809],\n",
       "         [916.7574,  12.8287],\n",
       "         [908.1885,  12.7466],\n",
       "         [908.0423,  27.9987]],\n",
       "\n",
       "        [[423.3223,  58.3731],\n",
       "         [431.5923,  58.0808],\n",
       "         [431.0707,  43.3233],\n",
       "         [422.8007,  43.6156]],\n",
       "\n",
       "        [[449.3544,  58.2894],\n",
       "         [456.8157,  58.1468],\n",
       "         [456.5508,  44.2832],\n",
       "         [449.0894,  44.4258]],\n",
       "\n",
       "        [[380.0982,  58.9879],\n",
       "         [390.1828,  58.9452],\n",
       "         [390.1151,  42.9451],\n",
       "         [380.0305,  42.9878]],\n",
       "\n",
       "        [[913.3897,  57.8419],\n",
       "         [913.8411,  45.0166],\n",
       "         [905.6977,  44.7300],\n",
       "         [905.2463,  57.5553]],\n",
       "\n",
       "        [[950.8419,  26.7492],\n",
       "         [958.8185,  26.6636],\n",
       "         [958.6584,  11.7594],\n",
       "         [950.6819,  11.8450]],\n",
       "\n",
       "        [[653.0206, 651.7175],\n",
       "         [659.0685, 632.8205],\n",
       "         [620.1555, 620.3668],\n",
       "         [614.1077, 639.2637]],\n",
       "\n",
       "        [[978.6019,  27.9515],\n",
       "         [978.7275,  12.4776],\n",
       "         [971.0120,  12.4150],\n",
       "         [970.8864,  27.8889]],\n",
       "\n",
       "        [[959.9560,  26.8184],\n",
       "         [967.2969,  26.8124],\n",
       "         [967.2844,  11.6318],\n",
       "         [959.9434,  11.6378]],\n",
       "\n",
       "        [[406.4988,  58.6251],\n",
       "         [415.3723,  58.3158],\n",
       "         [414.9052,  44.9158],\n",
       "         [406.0316,  45.2251]],\n",
       "\n",
       "        [[924.7330,  59.0932],\n",
       "         [925.2574,  46.5287],\n",
       "         [917.3293,  46.1978],\n",
       "         [916.8049,  58.7623]],\n",
       "\n",
       "        [[720.8134, 379.1585],\n",
       "         [757.9823, 364.8618],\n",
       "         [751.1010, 346.9714],\n",
       "         [713.9320, 361.2682]],\n",
       "\n",
       "        [[980.6927,  28.4453],\n",
       "         [988.7260,  28.3311],\n",
       "         [988.5016,  12.5469],\n",
       "         [980.4683,  12.6611]],\n",
       "\n",
       "        [[495.4645,  59.7633],\n",
       "         [495.6922,  45.8733],\n",
       "         [486.6211,  45.7246],\n",
       "         [486.3934,  59.6146]],\n",
       "\n",
       "        [[606.2818,  57.9046],\n",
       "         [615.0318,  57.6879],\n",
       "         [614.6613,  42.7287],\n",
       "         [605.9113,  42.9454]],\n",
       "\n",
       "        [[522.0201, 623.5010],\n",
       "         [528.3013, 602.8108],\n",
       "         [486.2172, 590.0350],\n",
       "         [479.9361, 610.7252]],\n",
       "\n",
       "        [[609.0808, 643.1042],\n",
       "         [615.6260, 623.2073],\n",
       "         [574.3429, 609.6271],\n",
       "         [567.7977, 629.5240]],\n",
       "\n",
       "        [[614.3926, 771.1610],\n",
       "         [626.0417, 756.5530],\n",
       "         [591.9579, 729.3728],\n",
       "         [580.3087, 743.9808]],\n",
       "\n",
       "        [[821.5927, 123.7366],\n",
       "         [821.7358, 111.8092],\n",
       "         [815.0204, 111.7286],\n",
       "         [814.8774, 123.6561]],\n",
       "\n",
       "        [[848.8378, 122.7348],\n",
       "         [849.2363, 112.4747],\n",
       "         [842.8766, 112.2277],\n",
       "         [842.4782, 122.4879]]], device='cuda:0')\n",
       "xyxyxyxyn: tensor([[[0.4108, 0.3396],\n",
       "         [0.4249, 0.3258],\n",
       "         [0.3987, 0.2936],\n",
       "         [0.3846, 0.3074]],\n",
       "\n",
       "        [[0.3936, 0.3570],\n",
       "         [0.4084, 0.3429],\n",
       "         [0.3819, 0.3096],\n",
       "         [0.3672, 0.3237]],\n",
       "\n",
       "        [[0.4375, 0.0616],\n",
       "         [0.4454, 0.0614],\n",
       "         [0.4451, 0.0478],\n",
       "         [0.4372, 0.0480]],\n",
       "\n",
       "        [[0.6173, 0.7051],\n",
       "         [0.6227, 0.6845],\n",
       "         [0.5840, 0.6722],\n",
       "         [0.5786, 0.6927]],\n",
       "\n",
       "        [[0.4496, 0.0629],\n",
       "         [0.4588, 0.0627],\n",
       "         [0.4586, 0.0475],\n",
       "         [0.4494, 0.0477]],\n",
       "\n",
       "        [[0.4163, 0.0606],\n",
       "         [0.4235, 0.0604],\n",
       "         [0.4230, 0.0450],\n",
       "         [0.4159, 0.0452]],\n",
       "\n",
       "        [[0.9010, 0.0295],\n",
       "         [0.9014, 0.0111],\n",
       "         [0.8926, 0.0109],\n",
       "         [0.8922, 0.0293]],\n",
       "\n",
       "        [[0.3759, 0.0609],\n",
       "         [0.3844, 0.0607],\n",
       "         [0.3842, 0.0467],\n",
       "         [0.3756, 0.0469]],\n",
       "\n",
       "        [[0.4321, 0.3178],\n",
       "         [0.4451, 0.3004],\n",
       "         [0.4145, 0.2729],\n",
       "         [0.4015, 0.2903]],\n",
       "\n",
       "        [[0.8866, 0.0290],\n",
       "         [0.8869, 0.0133],\n",
       "         [0.8785, 0.0131],\n",
       "         [0.8782, 0.0288]],\n",
       "\n",
       "        [[0.8746, 0.0294],\n",
       "         [0.8748, 0.0134],\n",
       "         [0.8666, 0.0134],\n",
       "         [0.8665, 0.0293]],\n",
       "\n",
       "        [[0.4039, 0.0612],\n",
       "         [0.4118, 0.0609],\n",
       "         [0.4113, 0.0454],\n",
       "         [0.4034, 0.0457]],\n",
       "\n",
       "        [[0.4288, 0.0611],\n",
       "         [0.4359, 0.0610],\n",
       "         [0.4356, 0.0464],\n",
       "         [0.4285, 0.0466]],\n",
       "\n",
       "        [[0.3627, 0.0618],\n",
       "         [0.3723, 0.0618],\n",
       "         [0.3722, 0.0450],\n",
       "         [0.3626, 0.0451]],\n",
       "\n",
       "        [[0.8716, 0.0606],\n",
       "         [0.8720, 0.0472],\n",
       "         [0.8642, 0.0469],\n",
       "         [0.8638, 0.0603]],\n",
       "\n",
       "        [[0.9073, 0.0280],\n",
       "         [0.9149, 0.0279],\n",
       "         [0.9148, 0.0123],\n",
       "         [0.9071, 0.0124]],\n",
       "\n",
       "        [[0.6231, 0.6831],\n",
       "         [0.6289, 0.6633],\n",
       "         [0.5918, 0.6503],\n",
       "         [0.5860, 0.6701]],\n",
       "\n",
       "        [[0.9338, 0.0293],\n",
       "         [0.9339, 0.0131],\n",
       "         [0.9265, 0.0130],\n",
       "         [0.9264, 0.0292]],\n",
       "\n",
       "        [[0.9160, 0.0281],\n",
       "         [0.9230, 0.0281],\n",
       "         [0.9230, 0.0122],\n",
       "         [0.9160, 0.0122]],\n",
       "\n",
       "        [[0.3879, 0.0615],\n",
       "         [0.3963, 0.0611],\n",
       "         [0.3959, 0.0471],\n",
       "         [0.3874, 0.0474]],\n",
       "\n",
       "        [[0.8824, 0.0619],\n",
       "         [0.8829, 0.0488],\n",
       "         [0.8753, 0.0484],\n",
       "         [0.8748, 0.0616]],\n",
       "\n",
       "        [[0.6878, 0.3974],\n",
       "         [0.7233, 0.3825],\n",
       "         [0.7167, 0.3637],\n",
       "         [0.6812, 0.3787]],\n",
       "\n",
       "        [[0.9358, 0.0298],\n",
       "         [0.9434, 0.0297],\n",
       "         [0.9432, 0.0132],\n",
       "         [0.9356, 0.0133]],\n",
       "\n",
       "        [[0.4728, 0.0626],\n",
       "         [0.4730, 0.0481],\n",
       "         [0.4643, 0.0479],\n",
       "         [0.4641, 0.0625]],\n",
       "\n",
       "        [[0.5785, 0.0607],\n",
       "         [0.5869, 0.0605],\n",
       "         [0.5865, 0.0448],\n",
       "         [0.5782, 0.0450]],\n",
       "\n",
       "        [[0.4981, 0.6536],\n",
       "         [0.5041, 0.6319],\n",
       "         [0.4639, 0.6185],\n",
       "         [0.4580, 0.6402]],\n",
       "\n",
       "        [[0.5812, 0.6741],\n",
       "         [0.5874, 0.6533],\n",
       "         [0.5480, 0.6390],\n",
       "         [0.5418, 0.6599]],\n",
       "\n",
       "        [[0.5863, 0.8083],\n",
       "         [0.5974, 0.7930],\n",
       "         [0.5648, 0.7645],\n",
       "         [0.5537, 0.7799]],\n",
       "\n",
       "        [[0.7840, 0.1297],\n",
       "         [0.7841, 0.1172],\n",
       "         [0.7777, 0.1171],\n",
       "         [0.7776, 0.1296]],\n",
       "\n",
       "        [[0.8100, 0.1287],\n",
       "         [0.8103, 0.1179],\n",
       "         [0.8043, 0.1176],\n",
       "         [0.8039, 0.1284]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].obb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from enum import Enum\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "class ModelClass(Enum):\n",
    "    NANO = \"nano\"\n",
    "    MEDIUM = \"med\"\n",
    "    LARGE = \"large\"\n",
    "\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, img_data_folder, image_gm, image_osm, parking_mask, model_type):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with paths and model type.\n",
    "\n",
    "        Args:\n",
    "            img_data_folder (str): Folder with image data (e.g., \"data/0/\")\n",
    "            image_gm (str): Name of Google Maps image (e.g., \"cropped_gm.png\")\n",
    "            image_osm (str): Name of OpenStreetMap image (e.g., \"cropped_osm.png\")\n",
    "            parking_mask (str): Name of mask image (e.g., \"cropped_osm_mask.png\")\n",
    "            model_type (ModelClass): Type of model to use (NANO, MEDIUM, LARGE)\n",
    "        \"\"\"\n",
    "        self.img_data_folder = img_data_folder\n",
    "        self.image_gm_path = os.path.join(img_data_folder, image_gm)\n",
    "        self.image_osm_path = os.path.join(img_data_folder, image_osm)\n",
    "        self.parking_mask_path = os.path.join(img_data_folder, parking_mask)\n",
    "        self.model_type = model_type\n",
    "\n",
    "        # Determine device\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Load model\n",
    "        model_name = f\"./runs/obb/train_{model_type.value}/weights/best.pt\"\n",
    "        self.model = YOLO(model_name)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.results = None\n",
    "\n",
    "    def load_images(self):\n",
    "        \"\"\"Load input images and mask.\"\"\"\n",
    "        self.img_gm = cv2.imread(self.image_gm_path)\n",
    "        self.img_osm = cv2.imread(self.image_osm_path)\n",
    "        self.mask = cv2.imread(self.parking_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    def is_in_mask(self, box_points):\n",
    "        \"\"\"\n",
    "        Check if a bounding box is within the masked area.\n",
    "\n",
    "        Args:\n",
    "            box_points: Array of (x,y) points defining the bounding box\n",
    "            threshold: Minimum percentage of box area that should be in masked area\n",
    "\n",
    "        Returns:\n",
    "            float: Ratio of box points in masked area\n",
    "        \"\"\"\n",
    "        # Convert tensor to numpy array if needed\n",
    "        if isinstance(box_points, torch.Tensor):\n",
    "            box_points = box_points.cpu().numpy()\n",
    "\n",
    "        # Create a polygon mask from the box points\n",
    "        box_mask = np.zeros_like(self.mask)\n",
    "        points = box_points.reshape((-1, 1, 2)).astype(np.int32)\n",
    "        cv2.fillPoly(box_mask, [points], 255)\n",
    "\n",
    "        # Count pixels in box that are also in mask\n",
    "        intersection = cv2.bitwise_and(box_mask, self.mask)\n",
    "        box_area = np.sum(box_mask > 0)\n",
    "        intersection_area = np.sum(intersection > 0)\n",
    "\n",
    "        # Return ratio of intersection area to box area\n",
    "        return intersection_area / box_area if box_area > 0 else 0\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Make predictions on the loaded images.\n",
    "\n",
    "        Returns:\n",
    "            list: List of results from the model prediction\n",
    "        \"\"\"\n",
    "        self.load_images()\n",
    "\n",
    "        # Make prediction on Google Maps image\n",
    "        self.results = self.model.predict(self.img_gm, device=self.device)\n",
    "\n",
    "        return self.results\n",
    "\n",
    "    def visualize(self, mask_threshold=0.7, mask_low_confidence=0.1, visualization_type=\"gm\", save_path=None):\n",
    "        \"\"\"\n",
    "        Create visualization.\n",
    "\n",
    "        Args:\n",
    "            confidence_threshold: Threshold for high confidence (green boxes)\n",
    "            low_confidence: Minimum threshold for low confidence (red boxes)\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Visualization image with colored boxes\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a visualization image (copy of the original)\n",
    "        assert visualization_type in [\"gm\", \"osm\"], \"Invalid visualization type\"\n",
    "        if visualization_type == \"gm\":\n",
    "            vis_img = self.img_gm.copy()\n",
    "        else:\n",
    "            vis_img = self.img_osm.copy()\n",
    "\n",
    "        # Process each detected object\n",
    "        for result in self.results:\n",
    "            if hasattr(result, \"obb\") and result.obb is not None:\n",
    "                for i, box in enumerate(result.obb.xyxyxyxy):\n",
    "                    conf = float(result.obb.conf[i])\n",
    "\n",
    "                    # Convert tensor to numpy if needed\n",
    "                    if isinstance(box, torch.Tensor):\n",
    "                        box = box.cpu().numpy()\n",
    "\n",
    "                    # Check if box is in masked area and get ratio\n",
    "                    mask_ratio = self.is_in_mask(box)\n",
    "\n",
    "                    # Only process boxes with sufficient confidence and mask overlap\n",
    "                    if mask_ratio >= mask_low_confidence:\n",
    "                        # Choose color based on confidence\n",
    "                        if mask_ratio >= mask_threshold:\n",
    "                            color = (0, 255, 0)  # Green for high confidence\n",
    "                        else:\n",
    "                            color = (0, 0, 255)  # Red for low confidence\n",
    "\n",
    "                        # Draw the oriented bounding box\n",
    "                        points = box.reshape((-1, 1, 2)).astype(np.int32)\n",
    "                        cv2.polylines(\n",
    "                            vis_img, [points], isClosed=True, color=color, thickness=2\n",
    "                        )\n",
    "\n",
    "                        # Get the minimum x and y for text positioning\n",
    "                        box_reshaped = box.reshape(4, 2)\n",
    "                        min_x = int(np.min(box_reshaped[:, 0]))\n",
    "                        min_y = int(np.min(box_reshaped[:, 1]))\n",
    "                        text_pos = (min_x, min_y - 10)\n",
    "                        \n",
    "                        # Add confidence score text\n",
    "                        cv2.putText(\n",
    "                            vis_img,\n",
    "                            f\"{conf:.2f}\",\n",
    "                            text_pos,\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,\n",
    "                            color,\n",
    "                            2,\n",
    "                        )\n",
    "        \n",
    "        # Save the visualization image if a path is provided\n",
    "        if save_path:\n",
    "            cv2.imwrite(os.path.join(self.img_data_folder, save_path), vis_img)\n",
    "            print(f\"Visualization saved to {save_path}\")\n",
    "\n",
    "        # Return the visualization image\n",
    "        return vis_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x640 13.7ms\n",
      "Speed: 3.4ms preprocess, 13.7ms inference, 5.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "Visualization saved to visualization_gm.png\n",
      "Visualization saved to visualization_osm.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[201, 208, 217],\n",
       "        [201, 208, 217],\n",
       "        [201, 208, 217],\n",
       "        ...,\n",
       "        [241, 243, 245],\n",
       "        [241, 243, 245],\n",
       "        [241, 243, 245]],\n",
       "\n",
       "       [[201, 208, 217],\n",
       "        [201, 208, 217],\n",
       "        [201, 208, 217],\n",
       "        ...,\n",
       "        [241, 243, 245],\n",
       "        [241, 243, 245],\n",
       "        [241, 243, 245]],\n",
       "\n",
       "       [[201, 208, 217],\n",
       "        [201, 208, 217],\n",
       "        [201, 208, 217],\n",
       "        ...,\n",
       "        [241, 243, 245],\n",
       "        [241, 243, 245],\n",
       "        [241, 243, 245]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the predictor\n",
    "predictor = Predictor(\n",
    "    img_data_folder=\"data/0/\",\n",
    "    image_gm=\"cropped_gm.png\",\n",
    "    image_osm=\"cropped_osm.png\",\n",
    "    parking_mask=\"cropped_osm_mask.png\",\n",
    "    model_type=ModelClass.LARGE,\n",
    ")\n",
    "\n",
    "results = predictor.predict()\n",
    "\n",
    "# Generate visualization\n",
    "predictor.visualize(\n",
    "    mask_threshold=0.5,\n",
    "    mask_low_confidence=0.1,\n",
    "    visualization_type=\"gm\",\n",
    "    save_path=\"visualization_gm.png\",\n",
    ")\n",
    "\n",
    "predictor.visualize(\n",
    "    mask_threshold=0.5,\n",
    "    mask_low_confidence=0.1,\n",
    "    visualization_type=\"osm\",\n",
    "    save_path=\"visualization_osm.png\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
